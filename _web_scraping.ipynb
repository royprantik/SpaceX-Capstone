{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Flight No.  \\\n",
      "0                                                 14   \n",
      "1  Following second-stage separation, SpaceX atte...   \n",
      "2                                                 15   \n",
      "3  First launch under USAF'sOSP3 launch contract....   \n",
      "4                                                 16   \n",
      "\n",
      "            Date and time ( )                            Launch site  \\\n",
      "0   10 January 2015,09:47[67]  F9 v1.1B1012[8]  Cape Canaveral,LC-40   \n",
      "1                        None             None                  None   \n",
      "2  11 February 2015,23:03[72]  F9 v1.1B1013[8]  Cape Canaveral,LC-40   \n",
      "3                        None             None                  None   \n",
      "4  2 March 2015,03:50[21][76]  F9 v1.1B1014[8]  Cape Canaveral,LC-40   \n",
      "\n",
      "                         Payload             Payload mass  \\\n",
      "0  SpaceX CRS-5[68](Dragon C107)  2,395 kg (5,280 lb)[69]   \n",
      "1                           None                     None   \n",
      "2                 DSCOVR[68][73]        570 kg (1,260 lb)   \n",
      "3                           None                     None   \n",
      "4  ABS-3AEutelsat 115 West B[68]      4,159 kg (9,169 lb)   \n",
      "\n",
      "                        Orbit      Customer Launch outcome  \\\n",
      "0                    LEO(ISS)     NASA(CRS)    Success[70]   \n",
      "1                        None          None           None   \n",
      "2  HEO(Sunâ€“Earth L1insertion)  USAFNASANOAA        Success   \n",
      "3                        None          None           None   \n",
      "4                         GTO   ABSEutelsat        Success   \n",
      "\n",
      "                         \n",
      "0   Failure(drone ship)  \n",
      "1                  None  \n",
      "2  Controlled(ocean)[d]  \n",
      "3                  None  \n",
      "4        No attempt[77]  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "class WikipediaTableScraper:\n",
    "    \n",
    "    def __init__(self, url, table_index=0):\n",
    "        self.url = url\n",
    "        self.table_index = table_index\n",
    "        self.soup = None\n",
    "        self.table = None\n",
    "        self.df = None\n",
    "\n",
    "    def fetch_html(self):\n",
    "        response = requests.get(self.url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\"Failed to fetch page\")\n",
    "        self.soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    def extract_table(self):\n",
    "        tables = self.soup.find_all(\"table\", {\"class\": [\"wikitable\", \"sortable\", \"plainrowheaders\", \"collapsible\"]})\n",
    "        if len(tables) <= self.table_index:\n",
    "            raise Exception(\"Table index out of range\")\n",
    "        self.table = tables[self.table_index]\n",
    "\n",
    "    def clean_header(self, header_row):\n",
    "        headers = []\n",
    "        for th in header_row.find_all('th'):\n",
    "            # Clean unwanted tags inside header\n",
    "            for tag in ['br', 'a', 'sup']:\n",
    "                if th.find(tag):\n",
    "                    th.find(tag).extract()\n",
    "            header = ' '.join(th.stripped_strings)\n",
    "            headers.append(header)\n",
    "        return headers\n",
    "\n",
    "    def parse_row(self, row):\n",
    "        cells = row.find_all(['th', 'td'])\n",
    "        values = []\n",
    "        for cell in cells:\n",
    "            # Normalize unicode and remove leading/trailing spaces\n",
    "            text = unicodedata.normalize(\"NFKD\", cell.get_text(strip=True))\n",
    "            values.append(text)\n",
    "        return values\n",
    "\n",
    "    def scrape(self):\n",
    "        self.fetch_html()\n",
    "        self.extract_table()\n",
    "\n",
    "        header_row = self.table.find('tr')\n",
    "        headers = self.clean_header(header_row)\n",
    "\n",
    "        rows_data = []\n",
    "        for row in self.table.find_all('tr')[1:]:\n",
    "            parsed_row = self.parse_row(row)\n",
    "            if parsed_row:  # ignore empty rows\n",
    "                rows_data.append(parsed_row)\n",
    "\n",
    "        self.df = pd.DataFrame(rows_data, columns=headers)\n",
    "        return self.df\n",
    "\n",
    "# ================== Example Usage =======================\n",
    "\n",
    "url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "scraper = WikipediaTableScraper(url, table_index=2)\n",
    "spacex_df = scraper.scrape()\n",
    "\n",
    "print(spacex_df.head())\n",
    "#this is the end version of wikipedia..any wikipedia page data i can get here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
